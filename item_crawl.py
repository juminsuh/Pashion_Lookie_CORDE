# --- [TOP: imports & globals] ---
import os, re, time, random, json, hashlib, argparse
import urllib.parse as urlparse
from dataclasses import dataclass, asdict
from typing import List, Tuple, Set, Dict

import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# ì €ì¥ í´ë”
SAVE_DIR = "/Users/minair/pme10/data/"
JSONL_DIR = os.path.join(SAVE_DIR, "jsonl")
IMAGE_DIR = os.path.join(SAVE_DIR, "image")  

# ì‚¬ì´íŠ¸ ê¸°ë³¸ ìƒìˆ˜
BASE = "https://www.musinsa.com"
NUM_COLLECT = 20 # ì„¸ë¶€ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ ê°œìˆ˜ for test

# ìŠ¤í¬ë¡¤/ëŒ€ê¸°
SCROLL_ROUNDS = 8
SCROLL_SLEEP = (0.9, 1.5)

# ì „ì—­ ì¤‘ë³µ ë°©ì§€ (ìƒí’ˆ ID)
SEEN_IDS: Set[str] = set()

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(SAVE_DIR, exist_ok=True)
os.makedirs(JSONL_DIR, exist_ok=True)
os.makedirs(IMAGE_DIR, exist_ok=True)

# ========= ë°ì´í„° ëª¨ë¸ =========
@dataclass
class ItemRow:
    ### for mangagement
    product_id: str
    gender: str
    main_cat_id: str
    main_cat_name: str
    sub_cat_id: str
    sub_cat_name: str
    product_name: str
    item_url: str
    brand: str
    price: str
    # color: List[str]
    img_dir: List[str]      
    img_url: List[str]       
    
    ### for recommendation
    style_id: str
    style_name: str
    texture_id: str    
    texture_name: str
    pattern_id: str
    pattern_name: str
    fit_id: str
    fit_name: str
    seasonality: str # ê²¨ìš¸ë¡œ ê³ ì •

def save_jsonl(data, filename):
    # í™•ì¥ìë¥¼ .jsonlë¡œ ë³€ê²½
    if not filename.endswith(".jsonl"):
        filename = re.sub(r"\.json$", "", filename) + ".jsonl"
        
    path = os.path.join(JSONL_DIR, filename)
    
    # ë¦¬ìŠ¤íŠ¸ ë°ì´í„°ë¼ë©´ í•œ ì¤„ì”© ë¶„ë¦¬í•´ì„œ ì €ì¥
    if isinstance(data, list):
        items_to_write = data
    else:
        items_to_write = [data]

    # 'a' (append) ëª¨ë“œë¡œ ì—´ì–´ì„œ í•œ ì¤„ì”© ì“°ê¸°
    with open(path, "a", encoding="utf-8") as f:
        for item in items_to_write:
            # ê°œí–‰ ë¬¸ì(\n)ë¥¼ ë¶™ì—¬ì„œ í•œ ì¤„ì”© ì €ì¥
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
    
    print(f"[INFO] Appended to JSONL -> {path} (+{len(items_to_write)} items)")

# ========= ë“œë¼ì´ë²„ =========
def make_driver(headless=True):
    opts = Options()
    if headless:
        opts.add_argument("--headless=new")
    opts.add_argument("--window-size=1400,2200")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-blink-features=AutomationControlled")
    opts.add_argument("--disable-extensions")
    opts.add_argument("--disable-plugins-discovery")
    driver = webdriver.Chrome(options=opts)
    driver.set_page_load_timeout(40)
    return driver

def build_category_url(gf: str, style_id: int, sub_cat_id: str=None) -> str:
    q = f"{BASE}/category/{main_cat_id}?gf={gf}&style={style_id}"
    if sub_cat_id:
        q += f"&category2Depth={sub_cat_id}"
    return q

def build_url(sub_cat_id: str, gf: str, style_id: int, texture_id: str, pattern_id: str, fit_id: str) -> str:
    q = f"{BASE}/category/{sub_cat_id}?gf={gf}&style={style_id}&attributeMaterial=1%{texture_id}&attributePattern=6%{pattern_id}&attributeFit=2%{fit_id}"
    return q

def extract_product_id(a_elem, href: str) -> str:
    pid = (a_elem.get_attribute("data-item-id") or "").strip()
    if pid:
        return pid
    m = re.search(r"/products/(\d+)", href)
    return m.group(1) if m else hashlib.md5(href.encode()).hexdigest()

# ì•„ì´í…œëª…ì—ì„œ 'ìƒí’ˆ ìƒì„¸ë¡œ ì´ë™' ê¼¬ë¦¬ ì œê±° + ê³µë°± ì •ë¦¬
def _clean_item_name(txt: str) -> str:
    if not txt:
        return ""
    txt = re.sub(r"\s*(ìƒí’ˆ\s*ìƒì„¸(?:ë¡œ)?\s*ì´ë™)\s*$", "", txt).strip()
    txt = re.sub(r"\s+", " ", txt)
    return txt

# ========= ìƒë‹¨ íƒ­: ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ (ì „ì²´ ì œì™¸) =========
def collect_subcategories(exclude_subcats, driver) -> List[Tuple[str, str]]:
    """
    íƒ­ ì»¨í…Œì´ë„ˆ(data-mds=TabText) ì•ˆì˜ 2ëìŠ¤ ì„¸ë¶€ì¹´í…Œê³ ë¦¬ë§Œ ìˆ˜ì§‘.
    'ì „ì²´' ë° data-category-id == main_cat_name_CODE(001) ì œì™¸.
    return: [(category_id, category_name)]
    """
    def _norm(s: str) -> str:
        s = (s or "").strip()
        return re.sub(r"\s+", " ", s)

    subs: List[Tuple[str, str]] = []

    try:
        # íƒ­ ì»¨í…Œì´ë„ˆê°€ ë Œë”ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        WebDriverWait(driver, 8).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '[data-mds="TabText"]'))
        )
        # íƒ­ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ ì¹´í…Œê³ ë¦¬ íƒ­ë§Œ ëŒ€ìƒ
        nodes = driver.find_elements(
            By.CSS_SELECTOR,
            '[data-mds="TabText"] [data-button-id="category"][data-category-id]'
        )
        for n in nodes:
            cid = (n.get_attribute("data-category-id") or "").strip()
            cname_full = (n.get_attribute("data-category-name") or "").strip()
            cname = cname_full.split("|")[-1] if "|" in cname_full else cname_full
            # í…ìŠ¤íŠ¸ ë°±ì—…
            if not cname:
                cname = _norm(n.text)
            cname = _norm(cname)

            # 'ì „ì²´'(í…ìŠ¤íŠ¸) ì œì™¸ + '001'(ë£¨íŠ¸ ì½”ë“œ) ì œì™¸
            if not cid or cid == main_cat_id or cname == "ì „ì²´":
                continue

            # 6ìë¦¬ ì¹´í…Œê³ ë¦¬ IDë§Œ í—ˆìš©
            if not re.fullmatch(r"\d{6}", cid):
                continue
            
            # âœ… ì œì™¸ ëª©ë¡ ì²´í¬
            exclude_ids = exclude_subcats.get('ids', [])
            exclude_names = exclude_subcats.get('names', [])
            
            if cid in exclude_ids or cname in exclude_names:
                print(f"ğŸ™… ì œì™¸: {cid} {cname}")
                continue

            subs.append((cid, cname))

    except Exception:
        pass

    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ë³´ì¡´)
    uniq, seen = [], set()
    for cid, cname in subs:
        key = f"{cid}|{cname}"
        if key not in seen:
            seen.add(key); uniq.append((cid, cname))
    print(f"ğŸ”— subcategories: {uniq}")
    return uniq

# def collect_subcategories(exclude_subcats, driver) -> List[Tuple[str, str]]:
#     """
#     íƒ­ ì»¨í…Œì´ë„ˆ(data-mds=TabText) ì•ˆì˜ 2ëìŠ¤ ì„¸ë¶€ì¹´í…Œê³ ë¦¬ë§Œ ìˆ˜ì§‘.
#     'ì „ì²´' ë° data-category-id == main_cat_name_CODE(001) ì œì™¸.
#     return: [(category_id, category_name)]
#     """
#     def _norm(s: str) -> str:
#         s = (s or "").strip()
#         return re.sub(r"\s+", " ", s)

#     subs: List[Tuple[str, str]] = []

#     try:
#         # íƒ­ ì»¨í…Œì´ë„ˆê°€ ë Œë”ë  ë•Œê¹Œì§€ ëŒ€ê¸°
#         WebDriverWait(driver, 8).until(
#             EC.presence_of_element_located((By.CSS_SELECTOR, '[data-mds="TabText"]'))
#         )
#         # íƒ­ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ ì¹´í…Œê³ ë¦¬ íƒ­ë§Œ ëŒ€ìƒ
#         nodes = driver.find_elements(
#             By.CSS_SELECTOR,
#             '[data-mds="TabText"] [data-button-id="category"]'
#         )
#         for n in nodes:
#             cid = (n.get_attribute("data-category-id") or "").strip()
#             cname_full = (n.get_attribute("data-category-name") or "").strip()
#             if '|' in cname_full:
#                 cname = cname_full.split("|"[-1])
#             else:
#                 cname = cname_full
                
#             if not cname:
#                 cname = _norm(n.text)

#             # 'ì „ì²´'(í…ìŠ¤íŠ¸) ì œì™¸ + '001'(ë£¨íŠ¸ ì½”ë“œ) ì œì™¸
#             if not cid or cid == main_cat_id or cname == "ì „ì²´":
#                 continue

#             # 6ìë¦¬ ì¹´í…Œê³ ë¦¬ IDë§Œ í—ˆìš©
#             if not re.fullmatch(r"\d{6}", cid):
#                 continue
            
#             # âœ… ì œì™¸ ëª©ë¡ ì²´í¬
#             exclude_ids = exclude_subcats.get('ids', [])
#             exclude_names = exclude_subcats.get('names', [])
            
#             if cid in exclude_ids or cname in exclude_names:
#                 print(f"ğŸ™… ì œì™¸: {cid} {cname}")
#                 continue

#             subs.append((cid, cname))

#     except Exception:
#         pass

#     # ì¤‘ë³µ ì œê±°(ìˆœì„œ ë³´ì¡´)
#     uniq, seen = [], set()
#     for cid, cname in subs:
#         key = f"{cid}|{cname}"
#         if key not in seen:
#             seen.add(key); uniq.append((cid, cname))
#     print(f"ğŸ”— subcategories: {uniq}")
#     return uniq

def click_subcategory(driver, cat_id: str, timeout: float = 6.0) -> bool:
    """
    ì„¸ë¶€ì¹´í…Œê³ ë¦¬ íƒ­(data-category-id=cat_id)ì„ í´ë¦­í•˜ê³  í™œì„±í™”(aria-current=true)ë  ë•Œê¹Œì§€ ëŒ€ê¸°.
    ë°˜í™˜: True(ì„±ê³µ) / False(ì‹¤íŒ¨)
    """
    try:
        # ëŒ€ìƒ íƒ­ ìš”ì†Œ
        tab = driver.find_element(By.CSS_SELECTOR, f'[data-mds="TabText"] [data-button-id="category"][data-category-id="{cat_id}"]')
        # ìŠ¤í¬ë¡¤í•´ì„œ ê°€ì‹œ ì˜ì—­ìœ¼ë¡œ
        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", tab)
        # í´ë¦­ (ì˜¤ë²„ë ˆì´ íšŒí”¼ìš© JS í´ë¦­ ìš°ì„ )
        try:
            driver.execute_script("arguments[0].click();", tab)
        except:
            tab.click()

        # í™œì„±í™”(aria-current=true)ê¹Œì§€ ëŒ€ê¸°
        WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located(
                (By.CSS_SELECTOR, f'[data-mds="TabText"] [data-button-id="category"][data-category-id="{cat_id}"][aria-current="true"]')
            )
        )

        # ìƒí’ˆ ê·¸ë¦¬ë“œê°€ ë‹¤ì‹œ ì±„ì›Œì§ˆ ë•Œê¹Œì§€ë„ ì§§ê²Œ ëŒ€ê¸°
        WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, 'a.gtm-select-item[href*="/products/"]'))
        )
        return True
    except Exception:
        return False

# ========= ë¦¬ìŠ¤íŠ¸: ë¸Œëœë“œ/ì•„ì´í…œëª…/URL ìˆ˜ì§‘ =========
def collect_list_minimals_unique(driver, need: int):
    """
    (product_id, brand, item_name, product_url) ë°˜í™˜ (ì „ì—­ SEEN_IDSë¡œ ì¤‘ë³µ ì œì™¸)
    """
    results, seen_local = [], set()
    rounds, last_cnt = 0, 0

    while len(results) < need and rounds < SCROLL_ROUNDS:
        try:
            WebDriverWait(driver, 12).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'a.gtm-select-item[href*="/products/"]'))
            )
        except: pass

        product_anchors = driver.find_elements(By.CSS_SELECTOR, 'a.gtm-select-item[href*="/products/"]')
        for a in product_anchors:
            href = (a.get_attribute("href") or "").split("?")[0]
            if "/products/" not in href:
                continue

            pid = extract_product_id(a, href)
            if pid in SEEN_IDS or pid in seen_local:
                continue

            # ----- ì•„ì´í…œëª… -----
            item_name = ""
            try:
                item_name = a.find_element(By.CSS_SELECTOR, 'span[data-mds="Typography"]').text.strip()
                item_name = _clean_item_name(item_name)
            except: item_name = ""
            if not item_name:
                item_name = _clean_item_name((a.get_attribute("aria-label") or "").strip())
            if not item_name or item_name in ("ìƒí’ˆìƒì„¸ë¡œ ì´ë™", "ìƒí’ˆ ìƒì„¸ë¡œ ì´ë™"):
                item_name = _clean_item_name((a.text or "").strip())
            if not item_name or item_name in ("ìƒí’ˆìƒì„¸ë¡œ ì´ë™", "ìƒí’ˆ ìƒì„¸ë¡œ ì´ë™"):
                try:
                    card = a.find_element(By.XPATH, "./ancestor::*[self::li or self::div][1]")
                    img = card.find_element(By.CSS_SELECTOR, "img[alt]")
                    item_name = _clean_item_name((img.get_attribute("alt") or "").strip())
                except: pass

            # ----- ë¸Œëœë“œëª… -----
            brand = ""
            try:
                card = a.find_element(By.XPATH, "./ancestor::*[self::li or self::div][1]")
                brand_span = card.find_element(By.CSS_SELECTOR, 'a[href*="/brand/"] span[data-mds="Typography"]')
                brand = brand_span.text.strip()
            except:
                brand = (a.get_attribute("data-brand-id") or a.get_attribute("data-item-brand") or "").strip()

            results.append((pid, brand, item_name, href))
            seen_local.add(pid)
            if len(results) >= need:
                break

        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(random.uniform(*SCROLL_SLEEP))
        rounds += 1
        if len(results) == last_cnt:
            break
        last_cnt = len(results)

    return results[:need]

# ========= ìƒì„¸: ê°€ê²©/ì´ë¯¸ì§€ë“¤/ì»¬ëŸ¬ =========
def download_images(
    img_urls: List[str],
    gender: str,
    category_name: str,
    subcategory_name: str,
    style_name: str,
    texture_name: str,
    pattern_name: str,
    fit_name: str,
    item_idx: int
) -> List[str]:
    """
    ì´ë¯¸ì§€ë“¤ì„ ë¬´ì‹ ì‚¬/image/[ì¹´í…Œê³ ë¦¬]_[ì„¸ë¶€ì¹´í…Œê³ ë¦¬]_[ìŠ¤íƒ€ì¼][ë²ˆí˜¸]/ ì•„ë˜ì— ì €ì¥
    íŒŒì¼ëª…ì€ 01.jpg, 02.jpg â€¦ ìˆœë²ˆ
    """
    saved_paths = []

    def _clean_name(x: str) -> str:
        x = (x or "").strip()
        x = re.sub(r"[\\/:*?\"<>|]", "_", x)   # ê¸ˆì§€ë¬¸ì â†’ "_"
        x = re.sub(r"\s+", " ", x)             # ê³µë°± ì •ë¦¬
        return x

    cat = _clean_name(category_name)
    sub = _clean_name(subcategory_name)
    pat = _clean_name(pattern_name)

    # âœ… í´ë”ëª…: [ì¹´í…Œê³ ë¦¬]_[ì„¸ë¶€ì¹´í…Œê³ ë¦¬]_[ìŠ¤íƒ€ì¼][ì•„ì´í…œë²ˆí˜¸]
    folder_name1 = f"{style_name}_{texture_name}_{pat}_{fit_name}"
    folder_name2 = f"{sub}_{item_idx:02d}"
    DETAIL_DIR = os.path.join(IMAGE_DIR, gender, cat)
    folder1 = os.path.join(DETAIL_DIR, folder_name1)
    folder2 = os.path.join(folder1, folder_name2)
    os.makedirs(folder2, exist_ok=True)

    headers = {"User-Agent": "Mozilla/5.0"}
    # print(f"ğŸ’¬ image_urls: {img_urls}")
    for idx, url in enumerate(img_urls, start=1):
        try:
            ext = ".jpg"
            m = re.search(r"\.(jpg|jpeg|png|webp)(?:\?|$)", url, re.I)
            if m:
                ext = "." + m.group(1).lower()

            filepath = os.path.join(folder2, f"{idx:02d}{ext}")

            r = requests.get(url, headers=headers, timeout=20)
            if r.status_code == 200:
                with open(filepath, "wb") as f:
                    f.write(r.content)
                saved_paths.append(filepath)
                # print("âœ… Images are downloaded!")
        except Exception as e:
            print(f"[WARN] image download failed: {url} ({e})")

    return saved_paths


def parse_detail(driver, url: str) -> Tuple[str, List[str], List[str], str]:
    """
    ìƒì„¸: ê°€ê²©(ì›ê°€), ìƒ‰ìƒ(ì»¬ëŸ¬ë§Œ), ëª¨ë“  ì„¬ë„¤ì¼ ì´ë¯¸ì§€ URL, product_id ë°˜í™˜
    """
    driver.get(url)
    try:
        WebDriverWait(driver, 12).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, 'img'))
        )
    except: pass
    time.sleep(0.6)

    # product_id ì¬ì¶”ì¶œ(ë³´ìˆ˜)
    m = re.search(r"/products/(\d+)", url)
    product_id = m.group(1) if m else hashlib.md5(url.encode()).hexdigest()

    # 1) ê°€ê²©(ì›ê°€)
    price_original = ""
    try:
        els = driver.find_elements(By.CSS_SELECTOR, ".line-through, del, s")
        texts = [e.text.strip() for e in els if (e.text or "").strip()]
        for t in texts:
            if re.search(r"\d[\d,]*\s*ì›", t):
                price_original = t; break
        if not price_original and texts:
            price_original = texts[0]
    except: pass

    # 2) ì´ë¯¸ì§€ ì¸ë„¤ì¼ë“¤ (ìš”êµ¬: ì œê³µëœ ì»¨í…Œì´ë„ˆ ë‚´ ì´ë¯¸ì§€ ì „ë¶€)
    #    ê¸°ë³¸ ì„ íƒì: div.sc-366fl4-2 ... ë‚´ë¶€ì˜ img[alt^="Thumbnail"]
    #    í´ë°±: ì¸ë„¤ì¼/ìƒì„¸ íŒ¨í„´ì´ ë“¤ì–´ê°„ ëª¨ë“  ì¸ë„¤ì¼ ì´ë¯¸ì§€
    image_urls = []
    try:
        thumbs = driver.find_elements(By.CSS_SELECTOR, 'div[class*="sc-366fl4-2"] img[alt^="Thumbnail"]')
        image_urls = [(im.get_attribute("src") or "").strip() for im in thumbs]
        image_urls = [u for u in image_urls if u]
    except: image_urls = []
    if not image_urls:
        imgs = driver.find_elements(By.CSS_SELECTOR, 'img')
        for im in imgs:
            src = (im.get_attribute("src") or "").strip()
            if not src: continue
            # ë¬´ì‹ ì‚¬ ì¸ë„¤ì¼/ìƒì„¸ ì´ë¯¸ì§€ íŒ¨í„´ í•„í„°
            if "image.msscdn.net/thumbnails" in src or "goods_img" in src or "prd_img" in src:
                image_urls.append(src)

    # 3) ì»¬ëŸ¬ ì˜µì…˜(ì»¬ëŸ¬ë§Œ)
    # colors = extract_colors(driver)  # ì‚¬ì´ì¦ˆ í•„í„°ë§ ë°˜ì˜

    # ì •ë¦¬: ì¤‘ë³µ ì œê±°
    def dedup(seq):
        out, seen = [], set()
        for x in seq:
            if x not in seen:
                seen.add(x); out.append(x)
        return out
    image_urls = dedup(image_urls)
    # colors = dedup(colors)

    return price_original, image_urls, product_id

# ========= ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ =========
def run_one_category(sub_cat_id: str, gf: str, style_id: int, texture_id: str, pattern_id: str, fit_id: str, gender: str, style_name: str,
                     sub_cat_name: str, texture_name: str, pattern_name: str, fit_name: str, NUM_COLLECT: int = 10, headless=True) -> List[Dict]:
    driver = make_driver(headless=headless)
    items: List[Dict] = []
    try:
        # 1) ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ íƒ­ì´ ìˆëŠ” í˜ì´ì§€ë¥¼ ë¨¼ì € ì˜¤í”ˆ (cat_id í¬í•¨/ë¹„í¬í•¨ ëª¨ë‘ í—ˆìš©)
        url = build_url(sub_cat_id, gf, style_id, texture_id, pattern_id, fit_id)  # â† cat_id ì—†ì´ ìƒë‹¨ íƒ­ ë³´ì¥
        print("[OPEN LIST]", url)
        driver.get(url)

        # íƒ­ë“¤ì´ ë³´ì¼ ë•Œê¹Œì§€
        WebDriverWait(driver, 12).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '[data-mds="TabText"]'))
        )

        # 2) ëª©í‘œ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ íƒ­ì„ í´ë¦­í•´ì„œ í™•ì •
        if sub_cat_id:
            ok = click_subcategory(driver, sub_cat_id)
            if not ok:
                print("âŒ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ íƒ­ í´ë¦­ ì‹¤íŒ¨")
                return []
                # ì‹¤íŒ¨ ì‹œ URL íŒŒë¼ë¯¸í„°ë¡œ ë‹¤ì‹œ ì§„ì… (í´ë°±), ê·¸ í›„ ë‹¤ì‹œ í´ë¦­ ì‹œë„
            #     driver.get(build_category_url(gf, style_id, sub_cat_id))
            #     WebDriverWait(driver, 8).until(
            #         EC.presence_of_element_located((By.CSS_SELECTOR, 'a.gtm-select-item[href*="/products/"]'))
            #     )
            #     re_ok = click_subcategory(driver, sub_cat_id)
            #     if not re_ok:
            #         print("âŒâŒ ì •ë§ ì‹¤íŒ¨")
            #     else:
            #         print("âœ… ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ íƒ­ í´ë¦­ ì„±ê³µ")
            # else:
            #     print("âœ… ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ íƒ­ í´ë¦­ ì„±ê³µ")

        # 3) ì´ì œ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
        minimal = collect_list_minimals_unique(driver, need=NUM_COLLECT)
        
        if not minimal:
            print(f"ğŸ“Œ ìˆ˜ì§‘í•  ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤: {gf}_{sub_cat_id}_{style_id}_{texture_id}_{pattern_id}_{fit_id}")
            return []
        
        print(f"ğŸ’¬ {len(minimal)}ê°œì˜ ìƒí’ˆ ìˆ˜ì§‘ ì‹œì‘...")
        for idx, (_, brand, item_name, href) in enumerate(minimal, start=1):
            price_o, img_urls, pid2 = parse_detail(driver, href)
            SEEN_IDS.add(pid2)

            saved_paths = download_images(
                img_urls,
                gender=gender,
                category_name=main_cat_name,
                subcategory_name=sub_cat_name,
                style_name=style_name,
                texture_name=texture_name,
                pattern_name=pattern_name,
                fit_name=fit_name,
                item_idx=idx
            )

            row = ItemRow(
                product_id=pid2,
                gender=gender,
                main_cat_id=main_cat_id,
                main_cat_name=main_cat_name,
                sub_cat_id=sub_cat_id,
                sub_cat_name=sub_cat_name,
                product_name=item_name,
                item_url=href,
                brand=brand,
                price=price_o,
                img_dir=saved_paths,
                img_url=img_urls,
                style_id=style_id,
                style_name=style_name,
                texture_id=texture_id,   
                texture_name=texture_name,
                pattern_id=pattern_id,
                pattern_name=pattern_name,
                fit_id=fit_id,
                fit_name=fit_name,
                seasonality="ê²¨ìš¸" # ê²¨ìš¸ë¡œ ê³ ì •
            )
            items.append(asdict(row))
            print(f"â¡ï¸ {idx}ë²ˆì§¸ ì•„ì´í…œ ìˆ˜ì§‘ ì™„ë£Œ!")
    finally:
        driver.quit()
    return items


def run_all(
    gender: str, 
    style_id:str, 
    texture_id: str,
    pattern_id: str,
    fit_id: str,
    NUM_COLLECT: int = 10, 
    headless=True) -> List[Dict]:
    """
    gender: 'ë‚¨' or 'ì—¬' (ê³µìš© ì œì™¸)  â†’ ë¬´ì‹ ì‚¬ íŒŒë¼ë¯¸í„°ëŠ” 'M'/'F'
    ê° ì„¸ë¶€ ì¹´í…Œê³ ë¦¬(â€˜ì „ì²´â€™ ì œì™¸)ë¥¼ ìˆœíšŒí•˜ë©° ìˆ˜ì§‘
    """
    gf_map = {"ë‚¨": "M", "ì—¬": "F"}
    gf = gf_map[gender]
    
    if main_cat_id == "001":
        exclude_subcats = {
            'ids': ['001001', '001008', '001011'],
            'names': ['ë°˜ì†Œë§¤ í‹°ì…”ì¸ ', 'ê¸°íƒ€ ìƒì˜', 'ë¯¼ì†Œë§¤ í‹°ì…”ì¸ ']
        }
    style_name_map = {1:"ìºì£¼ì–¼", 2:"ìŠ¤íŠ¸ë¦¿", 4:"ì›Œí¬ì›¨ì–´", 5:"í”„ë ˆí”¼",
                    9:"ê±¸ë¦¬ì‹œ", 12:"ì‹œí¬"}
    texture_name_map = {"5E3": "ë©´", "5E17": "í´ë¦¬ì—ìŠ¤í…Œë¥´", 
                  "5E43": "ìš¸", "5E29": "ë‚˜ì¼ë¡ ", "5E10": "ë‹ˆíŠ¸"}
    pattern_name_map = {"5E898": "ë¡œê³ /ê·¸ë˜í”½", "5E893": "ë‹¨ìƒ‰", 
                  "5E116": "ìŠ¤íŠ¸ë¼ì´í”„", "5E118": "ì²´í¬"}
    fit_name_map = {"5E90": "ì˜¤ë²„ì‚¬ì´ì¦ˆ", "5E88": "ë ˆê·¤ëŸ¬", "5E87": "ìŠ¬ë¦¼"}
    
    style_name = style_name_map[style_id]
    texture_name = texture_name_map[texture_id]
    pattern_name = pattern_name_map[pattern_id]
    fit_name = fit_name_map[fit_id]
    
    # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì–»ê¸° ìœ„í•´ ìƒìœ„ í˜ì´ì§€ í•œ ë²ˆ ì—´ê¸°
    driver = make_driver(headless=headless)
    subcats = []
    try:
        url = build_category_url(gf, style_id)
        print("[OPEN main_cat_name TABS]", url)
        driver.get(url)
        subcats = collect_subcategories(exclude_subcats, driver)  # [('001010','ê¸´ì†Œë§¤ í‹°ì…”ì¸ '), ...]  'ì „ì²´' ì œì™¸ë¨
    finally:
        driver.quit()

    if not subcats:
        print("[WARN] ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì§€ ëª»í•´ ìƒìœ„ ì¹´í…Œê³ ë¦¬ì—ì„œ ì§ì ‘ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        subcats = [(None, main_cat_name)]  # fallback

    all_items: List[Dict] = []
    for sub_cat_id, sub_cat_name in subcats:
        try:
            cat_items = run_one_category(sub_cat_id, gf, style_id, texture_id, pattern_id, fit_id, gender, style_name, sub_cat_name, texture_name, pattern_name, fit_name, NUM_COLLECT=NUM_COLLECT, headless=headless)
            all_items.extend(cat_items)
        except Exception as e:
            print(f"[WARN] category {sub_cat_id}/{sub_cat_name} failed: {e}")
    return all_items

def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument('--main_cat_id', type=str, default='001', help="ID of main category")
    parser.add_argument('--main_cat_name', type=str, default='ìƒì˜', help="Name of main category")
    parser.add_argument('--style_id', type=int, default=1)
    parser.add_argument('--texture_id', type=str, default="5E3")
    parser.add_argument('--pattern_id', type=str, default="5E898")
    parser.add_argument('--fit_id', type=str, default="5E90")

    args = parser.parse_args()
    return args

if __name__ == "__main__":
    data_all = []
    args = parse_arguments()
    main_cat_id = args.main_cat_id
    main_cat_name = args.main_cat_name
    style_id = args.style_id
    texture_id = args.texture_id
    pattern_id = args.pattern_id
    fit_id = args.fit_id

    for gender in ["ë‚¨", "ì—¬"]:   # âœ… ê³µìš© ì œì™¸
        print(f"ğŸ’â€â™€ï¸: {gender} í¬ë¡¤ë§ ì‹œì‘")
        items = run_all(
            gender=gender, 
            style_id=style_id,
            texture_id=texture_id,
            pattern_id=pattern_id,
            fit_id=fit_id,
            NUM_COLLECT=NUM_COLLECT, 
            headless=True)
        # ì„±ë³„ë³„ JSON ì €ì¥
        fname = f"{gender}_{main_cat_name}_{NUM_COLLECT}.json"
        save_jsonl(items, fname)
        data_all.extend(items)